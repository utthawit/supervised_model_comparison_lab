{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Supervised Learning Model Comparison\n",
    "\n",
    "---\n",
    "\n",
    "### Let us begin...\n",
    "\n",
    "Recall the `data science process`.\n",
    "   1. Define the problem.\n",
    "   2. Gather the data.\n",
    "   3. Explore the data.\n",
    "   4. Model the data.\n",
    "   5. Evaluate the model.\n",
    "   6. Answer the problem.\n",
    "\n",
    "In this lab, we're going to focus mostly on creating (and then comparing) many regression and classification models. Thus, we'll define the problem and gather the data for you.\n",
    "Most of the questions requiring a written response can be written in 2-3 sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Define the problem.\n",
    "\n",
    "You are a data scientist with a financial services company. Specifically, you want to leverage data in order to identify potential customers.\n",
    "\n",
    "If you are unfamiliar with \"401(k)s\" or \"IRAs,\" these are two types of retirement accounts. Very broadly speaking:\n",
    "- You can put money for retirement into both of these accounts.\n",
    "- The money in these accounts gets invested and hopefully has a lot more money in it when you retire.\n",
    "- These are a little different from regular bank accounts in that there are certain tax benefits to these accounts. Also, employers frequently match money that you put into a 401k.\n",
    "- If you want to learn more about them, check out [this site](https://www.nerdwallet.com/article/ira-vs-401k-retirement-accounts).\n",
    "\n",
    "We will tackle one regression problem and one classification problem today.\n",
    "- Regression: What features best predict one's income?\n",
    "- Classification: Predict whether or not one is eligible for a 401k.\n",
    "\n",
    "Check out the data dictionary [here](http://fmwww.bc.edu/ec-p/data/wooldridge2k/401KSUBS.DES).\n",
    "\n",
    "#### NOTE: When predicting `inc`, you should pretend as though you do not have access to the `e401k`, the `p401k` variable, and the `pira` variable. \n",
    "\n",
    "#### When predicting `e401k`, you may use the entire dataframe if you wish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import root_mean_squared_error, make_scorer, f1_score\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor, KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingRegressor, RandomForestRegressor, AdaBoostRegressor, \\\n",
    "BaggingClassifier, RandomForestClassifier, AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Gather the data.\n",
    "\n",
    "##### 1. Read in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "d401k_df = pd.read_csv('401ksubs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>e401k</th>\n",
       "      <th>inc</th>\n",
       "      <th>marr</th>\n",
       "      <th>male</th>\n",
       "      <th>age</th>\n",
       "      <th>fsize</th>\n",
       "      <th>nettfa</th>\n",
       "      <th>p401k</th>\n",
       "      <th>pira</th>\n",
       "      <th>incsq</th>\n",
       "      <th>agesq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>13.170</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>4.575</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>173.4489</td>\n",
       "      <td>1600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>61.230</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>154.000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3749.1130</td>\n",
       "      <td>1225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>12.858</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>165.3282</td>\n",
       "      <td>1936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>98.880</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>21.800</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9777.2540</td>\n",
       "      <td>1936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>22.614</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>18.450</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>511.3930</td>\n",
       "      <td>2809</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   e401k     inc  marr  male  age  fsize   nettfa  p401k  pira      incsq  \\\n",
       "0      0  13.170     0     0   40      1    4.575      0     1   173.4489   \n",
       "1      1  61.230     0     1   35      1  154.000      1     0  3749.1130   \n",
       "2      0  12.858     1     0   44      2    0.000      0     0   165.3282   \n",
       "3      0  98.880     1     1   44      2   21.800      0     0  9777.2540   \n",
       "4      0  22.614     0     0   53      1   18.450      0     0   511.3930   \n",
       "\n",
       "   agesq  \n",
       "0   1600  \n",
       "1   1225  \n",
       "2   1936  \n",
       "3   1936  \n",
       "4   2809  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# review sample\n",
    "d401k_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "e401k     0\n",
       "inc       0\n",
       "marr      0\n",
       "male      0\n",
       "age       0\n",
       "fsize     0\n",
       "nettfa    0\n",
       "p401k     0\n",
       "pira      0\n",
       "incsq     0\n",
       "agesq     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for null\n",
    "d401k_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>e401k</th>\n",
       "      <th>inc</th>\n",
       "      <th>marr</th>\n",
       "      <th>male</th>\n",
       "      <th>age</th>\n",
       "      <th>fsize</th>\n",
       "      <th>nettfa</th>\n",
       "      <th>p401k</th>\n",
       "      <th>pira</th>\n",
       "      <th>incsq</th>\n",
       "      <th>agesq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9275.000000</td>\n",
       "      <td>9275.000000</td>\n",
       "      <td>9275.000000</td>\n",
       "      <td>9275.000000</td>\n",
       "      <td>9275.000000</td>\n",
       "      <td>9275.000000</td>\n",
       "      <td>9275.000000</td>\n",
       "      <td>9275.000000</td>\n",
       "      <td>9275.000000</td>\n",
       "      <td>9275.000000</td>\n",
       "      <td>9275.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.392129</td>\n",
       "      <td>39.254641</td>\n",
       "      <td>0.628571</td>\n",
       "      <td>0.204420</td>\n",
       "      <td>41.080216</td>\n",
       "      <td>2.885067</td>\n",
       "      <td>19.071675</td>\n",
       "      <td>0.276226</td>\n",
       "      <td>0.254340</td>\n",
       "      <td>2121.192483</td>\n",
       "      <td>1793.652722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.488252</td>\n",
       "      <td>24.090002</td>\n",
       "      <td>0.483213</td>\n",
       "      <td>0.403299</td>\n",
       "      <td>10.299517</td>\n",
       "      <td>1.525835</td>\n",
       "      <td>63.963838</td>\n",
       "      <td>0.447154</td>\n",
       "      <td>0.435513</td>\n",
       "      <td>3001.469424</td>\n",
       "      <td>895.648841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.008000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-502.302000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.160100</td>\n",
       "      <td>625.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.660000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>469.155600</td>\n",
       "      <td>1089.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>33.288000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1108.091000</td>\n",
       "      <td>1600.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>50.160000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>18.449500</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2516.025500</td>\n",
       "      <td>2304.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>199.041000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>1536.798000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>39617.320000</td>\n",
       "      <td>4096.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             e401k          inc         marr         male          age  \\\n",
       "count  9275.000000  9275.000000  9275.000000  9275.000000  9275.000000   \n",
       "mean      0.392129    39.254641     0.628571     0.204420    41.080216   \n",
       "std       0.488252    24.090002     0.483213     0.403299    10.299517   \n",
       "min       0.000000    10.008000     0.000000     0.000000    25.000000   \n",
       "25%       0.000000    21.660000     0.000000     0.000000    33.000000   \n",
       "50%       0.000000    33.288000     1.000000     0.000000    40.000000   \n",
       "75%       1.000000    50.160000     1.000000     0.000000    48.000000   \n",
       "max       1.000000   199.041000     1.000000     1.000000    64.000000   \n",
       "\n",
       "             fsize       nettfa        p401k         pira         incsq  \\\n",
       "count  9275.000000  9275.000000  9275.000000  9275.000000   9275.000000   \n",
       "mean      2.885067    19.071675     0.276226     0.254340   2121.192483   \n",
       "std       1.525835    63.963838     0.447154     0.435513   3001.469424   \n",
       "min       1.000000  -502.302000     0.000000     0.000000    100.160100   \n",
       "25%       2.000000    -0.500000     0.000000     0.000000    469.155600   \n",
       "50%       3.000000     2.000000     0.000000     0.000000   1108.091000   \n",
       "75%       4.000000    18.449500     1.000000     1.000000   2516.025500   \n",
       "max      13.000000  1536.798000     1.000000     1.000000  39617.320000   \n",
       "\n",
       "             agesq  \n",
       "count  9275.000000  \n",
       "mean   1793.652722  \n",
       "std     895.648841  \n",
       "min     625.000000  \n",
       "25%    1089.000000  \n",
       "50%    1600.000000  \n",
       "75%    2304.000000  \n",
       "max    4096.000000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d401k_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. What are 2-3 other variables that, if available, would be helpful to have?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "- Debt: Total debt (loans, credit card debt)\n",
    "- Savings Rate: Percentage of income saved each year\n",
    "- Risk Tolerance: Individual's willingness to take on investment risk."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Suppose a peer recommended putting `race` into your model in order to better predict who to target when advertising IRAs and 401(k)s. Why would this be an unethical decision?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "It could lead to discriminatory practices, as certain racial groups might be excluded or targeted disproportionately, regardless of their actual financial needs or potential."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Explore the data.\n",
    "\n",
    "##### 4. When attempting to predict income, which feature(s) would we reasonably not use? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate income by taking the square root of incsq, which is derived from inc squared."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5. What two variables have already been created for us through feature engineering? Come up with a hypothesis as to why subject-matter experts may have done this.\n",
    "> This need not be a \"statistical hypothesis.\" Just brainstorm why SMEs (Subject Matter Experts) might have done this!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `incsq` is income ^ 2\n",
    "- `agesq` is age ^ 2\n",
    "\n",
    "Subject Matter Experts might have created these squared terms to capture non-linear relationships."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6. Looking at the data dictionary, one variable description appears to be an error. What is this error, and what do you think the correct value would be?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `inc` it should be `income` not income ^ 2 as dictionary say.\n",
    "- `age` it should be `age` not age ^ 2 as dictionary say."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Model the data. (Part 1: Regression Problem)\n",
    "\n",
    "Recall:\n",
    "- Problem: What features best predict one's income?\n",
    "- When predicting `inc`, you should pretend as though you do not have access to the `e401k`, the `p401k` variable, and the `pira` variable.\n",
    "\n",
    "##### 7. List all modeling tactics we've learned that could be used to solve a regression problem (as of Wednesday afternoon of Week 6). For each tactic, identify whether it is or is not appropriate for solving this specific regression problem and explain why or why not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "- Linear Regression: Suitable for linear relationships\n",
    "- Gradient Boosting: It can handles complex relationships\n",
    "- Gradient Descent: Would be used to iteratively adjust the model minimize the difference between predicted income and actual income"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 8. Regardless of your answer to number 7, fit at least one of each of the following models to attempt to solve the regression problem above:\n",
    "    - a multiple linear regression model\n",
    "    - a k-nearest neighbors model\n",
    "    - a decision tree\n",
    "    - a set of bagged decision trees\n",
    "    - a random forest\n",
    "    - an Adaboost model\n",
    "    \n",
    "> As always, be sure to do a train/test split! In order to compare modeling techniques, you should use the same train-test split on each. I recommend setting a random seed here.\n",
    "\n",
    "> You may find it helpful to set up a pipeline to try each modeling technique, but you are not required to do so!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize values\n",
    "\n",
    "X = d401k_df[['marr','male','age','agesq','fsize','nettfa']]\n",
    "y = d401k_df['inc']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale value\n",
    "sc = StandardScaler()\n",
    "X_train_sc = sc.fit_transform(X_train)\n",
    "X_test_sc = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_models = {\n",
    "    'LR': LinearRegression(),\n",
    "    'KNN': KNeighborsRegressor(),\n",
    "    'DCT': DecisionTreeRegressor(),\n",
    "    'BAG': BaggingRegressor(),\n",
    "    'RF': RandomForestRegressor(),\n",
    "    'ADA': AdaBoostRegressor(),\n",
    "}\n",
    "\n",
    "search_params = {\n",
    "    'LR': {},\n",
    "    'KNN': {'n_neighbors': [1, 3, 5, 7]},\n",
    "    'DCT': {'max_depth': [None, 10, 15, 30, 50], 'min_samples_split': [0.001, 0.01, 0.1, 1.0], 'min_samples_leaf': [1, 2, 4, 8]},\n",
    "    'BAG': {'n_estimators': [10, 15, 30, 50, 100]},\n",
    "    'RF': {'n_estimators': [10, 15, 30, 50, 100], 'max_depth': [None, 5, 10, 15]},\n",
    "    'ADA': {'n_estimators': [10, 15, 30, 50, 100], 'learning_rate': [0.001, 0.01, 0.1, 1.0]},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Estimator of LinearRegression() is LinearRegression()\n",
      "Best Score of LinearRegression() is 0.28311732\n",
      "Training Score of LinearRegression() is 0.29257484\n",
      "Testing Score of LinearRegression() is 0.27494825\n",
      "Difference Training/Testing Score of LinearRegression() is 0.01762659\n",
      "--------------------------------------------------------------------------------\n",
      "Best Estimator of KNeighborsRegressor() is KNeighborsRegressor(n_neighbors=7)\n",
      "Best Score of KNeighborsRegressor() is 0.30340663\n",
      "Training Score of KNeighborsRegressor() is 0.48741439\n",
      "Testing Score of KNeighborsRegressor() is 0.33819723\n",
      "Difference Training/Testing Score of KNeighborsRegressor() is 0.14921716\n",
      "--------------------------------------------------------------------------------\n",
      "Best Estimator of DecisionTreeRegressor() is DecisionTreeRegressor(min_samples_leaf=2, min_samples_split=0.1)\n",
      "Best Score of DecisionTreeRegressor() is 0.37222742\n",
      "Training Score of DecisionTreeRegressor() is 0.38579921\n",
      "Testing Score of DecisionTreeRegressor() is 0.36759318\n",
      "Difference Training/Testing Score of DecisionTreeRegressor() is 0.01820604\n",
      "--------------------------------------------------------------------------------\n",
      "Best Estimator of BaggingRegressor() is BaggingRegressor(n_estimators=100)\n",
      "Best Score of BaggingRegressor() is 0.29747430\n",
      "Training Score of BaggingRegressor() is 0.89569576\n",
      "Testing Score of BaggingRegressor() is 0.31481534\n",
      "Difference Training/Testing Score of BaggingRegressor() is 0.58088042\n",
      "--------------------------------------------------------------------------------\n",
      "Best Estimator of RandomForestRegressor() is RandomForestRegressor(max_depth=5)\n",
      "Best Score of RandomForestRegressor() is 0.39849233\n",
      "Training Score of RandomForestRegressor() is 0.43362986\n",
      "Testing Score of RandomForestRegressor() is 0.39364812\n",
      "Difference Training/Testing Score of RandomForestRegressor() is 0.03998174\n",
      "--------------------------------------------------------------------------------\n",
      "Best Estimator of AdaBoostRegressor() is AdaBoostRegressor(learning_rate=0.01, n_estimators=100)\n",
      "Best Score of AdaBoostRegressor() is 0.36247606\n",
      "Training Score of AdaBoostRegressor() is 0.37731999\n",
      "Testing Score of AdaBoostRegressor() is 0.34932249\n",
      "Difference Training/Testing Score of AdaBoostRegressor() is 0.02799750\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# testing model, evaluate with R^2\n",
    "for name, model in test_models.items():\n",
    "    grid = GridSearchCV(estimator=model, param_grid=search_params[name], scoring='r2', cv=5, n_jobs=8)\n",
    "    grid.fit(X_train_sc, y_train)\n",
    "    print(f\"Best Estimator of {model} is {grid.best_estimator_}\")\n",
    "    print(f\"Best Score of {model} is {grid.best_score_:.8f}\")\n",
    "    print(f\"Training Score of {model} is {grid.score(X_train_sc, y_train):.8f}\")\n",
    "    print(f\"Testing Score of {model} is {grid.score(X_test_sc, y_test):.8f}\")\n",
    "    print(f\"Difference Training/Testing Score of {model} is {grid.score(X_train_sc, y_train) - grid.score(X_test_sc, y_test):.8f}\")\n",
    "    print('-'*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>nettfa</td>\n",
       "      <td>0.702537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>marr</td>\n",
       "      <td>0.235889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>agesq</td>\n",
       "      <td>0.027085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>age</td>\n",
       "      <td>0.025699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>male</td>\n",
       "      <td>0.005446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fsize</td>\n",
       "      <td>0.003344</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Feature  Importance\n",
       "5  nettfa    0.702537\n",
       "0    marr    0.235889\n",
       "3   agesq    0.027085\n",
       "2     age    0.025699\n",
       "1    male    0.005446\n",
       "4   fsize    0.003344"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best model is RandomForestRegressor(max_depth=5)\n",
    "# Display the relative importance of each feature in the model\n",
    "model = RandomForestRegressor(max_depth=5)\n",
    "model.fit(X_train_sc, y_train)\n",
    "importance_df = pd.DataFrame({'Feature': X_train.columns,\n",
    "                              'Importance': model.feature_importances_}) \\\n",
    "                            .sort_values(by='Importance', ascending=False)\n",
    "importance_df\n",
    "# Nettfa is the feature with the highest predictive power."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 9. What is bootstrapping?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "The bootstrap method is a resampling technique that involves repeatedly drawing samples from a data set with replacement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 10. What is the difference between a decision tree and a set of bagged decision trees? Be specific and precise!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "- Decision trees are single models that can be lead to overfitting.\n",
    "- Bagged decision trees are ensembles of multiple decision trees that can reduce overfitting and improve performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 11. What is the difference between a set of bagged decision trees and a random forest? Be specific and precise!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bagging and random forest are both ensemble techniques that use decision trees.\n",
    "- Bagging reduces variance by averaging multiple trees.\n",
    "- Random forest further improves performance by introducing feature randomness."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 12. Why might a random forest be superior to a set of bagged decision trees?\n",
    "> Hint: Consider the bias-variance tradeoff."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "Random forests are generally superior to bagged decision trees because they introduce additional randomness by considering only a subset of features at each split, further reducing correlation between trees and improving \n",
    "performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Evaluate the model. (Part 1: Regression Problem)\n",
    "\n",
    "##### 13. Using RMSE, evaluate each of the models you fit on both the training and testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Estimator of LinearRegression() is LinearRegression()\n",
      "Best Score of LinearRegression() is 20.28457138101961\n",
      "Training Score of LinearRegression() is 20.164244947447397\n",
      "Testing Score of LinearRegression() is 20.897416610818777\n",
      "Difference Training/Testing Score of LinearRegression() is -0.7331716633713796\n",
      "--------------------------------------------------------------------------------\n",
      "Best Estimator of KNeighborsRegressor() is KNeighborsRegressor(n_neighbors=7)\n",
      "Best Score of KNeighborsRegressor() is 19.999444960091047\n",
      "Training Score of KNeighborsRegressor() is 17.16425342367413\n",
      "Testing Score of KNeighborsRegressor() is 19.96514133648189\n",
      "Difference Training/Testing Score of KNeighborsRegressor() is -2.8008879128077595\n",
      "--------------------------------------------------------------------------------\n",
      "Best Estimator of DecisionTreeRegressor() is DecisionTreeRegressor(min_samples_split=0.1)\n",
      "Best Score of DecisionTreeRegressor() is 18.983492502580713\n",
      "Training Score of DecisionTreeRegressor() is 18.78870710629487\n",
      "Testing Score of DecisionTreeRegressor() is 19.516699348341557\n",
      "Difference Training/Testing Score of DecisionTreeRegressor() is -0.7279922420466889\n",
      "--------------------------------------------------------------------------------\n",
      "Best Estimator of BaggingRegressor() is BaggingRegressor(n_estimators=100)\n",
      "Best Score of BaggingRegressor() is 20.066524906397575\n",
      "Training Score of BaggingRegressor() is 7.773927679084401\n",
      "Testing Score of BaggingRegressor() is 20.276264273672282\n",
      "Difference Training/Testing Score of BaggingRegressor() is -12.50233659458788\n",
      "--------------------------------------------------------------------------------\n",
      "Best Estimator of RandomForestRegressor() is RandomForestRegressor(max_depth=5)\n",
      "Best Score of RandomForestRegressor() is 18.595133259599418\n",
      "Training Score of RandomForestRegressor() is 18.050270532656082\n",
      "Testing Score of RandomForestRegressor() is 19.11285910569121\n",
      "Difference Training/Testing Score of RandomForestRegressor() is -1.0625885730351285\n",
      "--------------------------------------------------------------------------------\n",
      "Best Estimator of AdaBoostRegressor() is AdaBoostRegressor(learning_rate=0.1, n_estimators=10)\n",
      "Best Score of AdaBoostRegressor() is 19.13163683857387\n",
      "Training Score of AdaBoostRegressor() is 18.941209170875688\n",
      "Testing Score of AdaBoostRegressor() is 19.886389703900836\n",
      "Difference Training/Testing Score of AdaBoostRegressor() is -0.9451805330251482\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# testing model, evaluate with (neg)RMSE\n",
    "for name, model in test_models.items():\n",
    "    grid = GridSearchCV(estimator=model, param_grid=search_params[name], scoring='neg_root_mean_squared_error', cv=5, n_jobs=8)\n",
    "    grid.fit(X_train_sc, y_train)\n",
    "    print(f\"Best Estimator of {model} is {grid.best_estimator_}\")\n",
    "    print(f\"Best Score of {model} is {abs(grid.best_score_)}\")\n",
    "    print(f\"Training Score of {model} is {abs(grid.score(X_train_sc, y_train))}\")\n",
    "    print(f\"Testing Score of {model} is {abs(grid.score(X_test_sc, y_test))}\")\n",
    "    print(f\"Difference Training/Testing Score of {model} is {abs(grid.score(X_train_sc, y_train)) - abs(grid.score(X_test_sc, y_test))}\")\n",
    "    print('-'*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 14. Based on training RMSE and testing RMSE, is there evidence of overfitting in any of your models? Which ones?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "It doesn't overfit except KNeighborsRegressor and BaggingRegressor, as the RMSE remains relatively the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 15. Based on everything we've covered so far, if you had to pick just one model as your final model to use to answer the problem in front of you, which one model would you pick? Defend your choice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "DecisionTreeRegressor is a suitable model due to its strong performance and lack of overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 16. Suppose you wanted to improve the performance of your final model. Brainstorm 2-3 things that, if you had more time, you would attempt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "- Conduct research into potential new features\n",
    "- Refine hyperparameters through GridSearch\n",
    "- Perform feature engineering and selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Model the data. (Part 2: Classification Problem)\n",
    "\n",
    "Recall:\n",
    "- Problem: Predict whether or not one is eligible for a 401k.\n",
    "- When predicting `e401k`, you may use the entire dataframe if you wish.\n",
    "\n",
    "##### 17. While you're allowed to use every variable in your dataframe, mention at least one disadvantage of using `p401k` in your model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "- It trend to overfit our model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 18. List all modeling tactics we've learned that could be used to solve a classification problem (as of Wednesday afternoon of Week 6). For each tactic, identify whether it is or is not appropriate for solving this specific classification problem and explain why or why not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Logistic Regression is well-suited for binary classification tasks.\n",
    "- KNN is a non-parametric algorithm but can be sensitive to noise and outliers.\n",
    "- Decision Trees can handle both categorical and numerical data and are robust to outliers.\n",
    "- Random Forests can mitigate overfitting through feature sampling.\n",
    "- AdaBoost provides insights into feature importance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 19. Regardless of your answer to number 18, fit at least one of each of the following models to attempt to solve the classification problem above:\n",
    "    - a logistic regression model\n",
    "    - a k-nearest neighbors model\n",
    "    - a decision tree\n",
    "    - a set of bagged decision trees\n",
    "    - a random forest\n",
    "    - an Adaboost model\n",
    "    \n",
    "> As always, be sure to do a train/test split! In order to compare modeling techniques, you should use the same train-test split on each. I recommend using a random seed here.\n",
    "\n",
    "> You may find it helpful to set up a pipeline to try each modeling technique, but you are not required to do so!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_models = {\n",
    "    'LR': LogisticRegression(),\n",
    "    'KNN': KNeighborsClassifier(),\n",
    "    'DCT': DecisionTreeClassifier(),\n",
    "    'BAG': BaggingClassifier(),\n",
    "    'RF': RandomForestClassifier(),\n",
    "    'ADA': AdaBoostClassifier()\n",
    "}\n",
    "\n",
    "search_params = {\n",
    "    'LR': {'solver': ['lbfgs', 'liblinear'], 'C': [0.001, 0.01, 0.1, 1]},\n",
    "    'KNN': {'n_neighbors': [1, 3, 5, 7]},\n",
    "    'DCT': {'max_depth': [None, 10, 20, 30]},\n",
    "    'BAG': {'n_estimators': [10, 15, 30, 50]},\n",
    "    'RF': {'n_estimators': [10, 15, 30, 50], 'max_depth': [None, 5, 15, 30]},\n",
    "    'ADA': {'n_estimators': [10, 15, 30, 50], 'learning_rate': [0.001, 0.01, 0.1, 1], 'algorithm': ['SAMME']},\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Evaluate the model. (Part 2: Classfication Problem)\n",
    "\n",
    "##### 20. Suppose our \"positive\" class is that someone is eligible for a 401(k). What are our false positives? What are our false negatives?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- False Positive: Predicts that an individual is eligible for 401(k), when in reality they are not.\n",
    "- False Negative: Predicts that an individual is ineligible for 401(k), when in reality they are eligible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize values\n",
    "X = d401k_df.drop(columns=['e401k','p401k'])\n",
    "y = d401k_df['e401k']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale values\n",
    "sc = StandardScaler()\n",
    "X_train_sc = sc.fit_transform(X_train)\n",
    "X_test_sc = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "e401k\n",
       "0    60.79\n",
       "1    39.21\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the baseline\n",
    "y.value_counts(normalize=True).mul(100).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 21. In this specific case, would we rather minimize false positives or minimize false negatives? Defend your choice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "- Minimizing false negatives is more desirable.\n",
    "- Result in an individual missing out on valuable retirement savings opportunities, potentially leading to financial hardship in their later years."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 22. Suppose we wanted to optimize for the answer you provided in problem 21. Which metric would we optimize in this case?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Specificity measures the proportion of actual negatives that are correctly identified as negative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 23. Suppose that instead of optimizing for the metric in problem 21, we wanted to balance our false positives and false negatives using `f1-score`. Why might [f1-score](https://en.wikipedia.org/wiki/F1_score) be an appropriate metric to use here?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F1 provides a balanced measure of both false positives and false negatives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 24. Using f1-score, evaluate each of the models you fit on both the training and testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Estimator of LogisticRegression() is LogisticRegression(C=1, solver='liblinear')\n",
      "Best Score of LogisticRegression() is 0.47012010\n",
      "Training F1-Score of LogisticRegression() is 0.65404313\n",
      "Testing F1-Score of LogisticRegression() is 0.66361186\n",
      "Difference Training/Testing F1-Score of LogisticRegression() is -0.00956873\n",
      "--------------------------------------------------------------------------------\n",
      "Best Estimator of KNeighborsClassifier() is KNeighborsClassifier(n_neighbors=7)\n",
      "Best Score of KNeighborsClassifier() is 0.47906587\n",
      "Training F1-Score of KNeighborsClassifier() is 0.73045822\n",
      "Testing F1-Score of KNeighborsClassifier() is 0.63665768\n",
      "Difference Training/Testing F1-Score of KNeighborsClassifier() is 0.09380054\n",
      "--------------------------------------------------------------------------------\n",
      "Best Estimator of DecisionTreeClassifier() is DecisionTreeClassifier(max_depth=10)\n",
      "Best Score of DecisionTreeClassifier() is 0.53168399\n",
      "Training F1-Score of DecisionTreeClassifier() is 0.76792453\n",
      "Testing F1-Score of DecisionTreeClassifier() is 0.65498652\n",
      "Difference Training/Testing F1-Score of DecisionTreeClassifier() is 0.11293801\n",
      "--------------------------------------------------------------------------------\n",
      "Best Estimator of BaggingClassifier() is BaggingClassifier(n_estimators=15)\n",
      "Best Score of BaggingClassifier() is 0.52408999\n",
      "Training F1-Score of BaggingClassifier() is 0.99231806\n",
      "Testing F1-Score of BaggingClassifier() is 0.63881402\n",
      "Difference Training/Testing F1-Score of BaggingClassifier() is 0.35350404\n",
      "--------------------------------------------------------------------------------\n",
      "Best Estimator of RandomForestClassifier() is RandomForestClassifier(max_depth=5, n_estimators=10)\n",
      "Best Score of RandomForestClassifier() is 0.54440029\n",
      "Training F1-Score of RandomForestClassifier() is 0.69716981\n",
      "Testing F1-Score of RandomForestClassifier() is 0.68355795\n",
      "Difference Training/Testing F1-Score of RandomForestClassifier() is 0.01361186\n",
      "--------------------------------------------------------------------------------\n",
      "Best Estimator of AdaBoostClassifier() is AdaBoostClassifier(algorithm='SAMME', learning_rate=0.01, n_estimators=15)\n",
      "Best Score of AdaBoostClassifier() is 0.59063915\n",
      "Training F1-Score of AdaBoostClassifier() is 0.64824798\n",
      "Testing F1-Score of AdaBoostClassifier() is 0.64204852\n",
      "Difference Training/Testing F1-Score of AdaBoostClassifier() is 0.00619946\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# testing model with F1 score\n",
    "for name, model in test_models.items():\n",
    "    grid = GridSearchCV(estimator=model, param_grid=search_params[name], scoring='f1', cv=5, n_jobs=8)\n",
    "    grid.fit(X_train_sc, y_train)\n",
    "    \n",
    "    best_model = grid.best_estimator_\n",
    "    best_model.fit(X_train_sc, y_train)\n",
    "    y_train_pred = best_model.predict(X_train_sc)\n",
    "    y_test_pred = best_model.predict(X_test_sc)\n",
    "    print(f\"Best Estimator of {model} is {grid.best_estimator_}\")\n",
    "    print(f\"Best Score of {model} is {grid.best_score_:.8f}\")\n",
    "    print(f\"Training F1-Score of {model} is {best_model.score(X_train_sc, y_train):.8f}\")\n",
    "    print(f\"Testing F1-Score of {model} is {best_model.score(X_test_sc, y_test):.8f}\")\n",
    "    print(f\"Difference Training/Testing F1-Score of {model} is {best_model.score(X_train_sc, y_train) - best_model.score(X_test_sc, y_test):.8f}\")\n",
    "    print('-'*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>nettfa</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>inc</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>marr</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>male</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>age</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fsize</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>pira</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>incsq</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>agesq</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Feature  Importance\n",
       "5  nettfa         1.0\n",
       "0     inc         0.0\n",
       "1    marr         0.0\n",
       "2    male         0.0\n",
       "3     age         0.0\n",
       "4   fsize         0.0\n",
       "6    pira         0.0\n",
       "7   incsq         0.0\n",
       "8   agesq         0.0"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best model is AdaBoostClassifier(algorithm='SAMME', learning_rate=0.01, n_estimators=15)\n",
    "# Display the relative importance of each feature in the model\n",
    "model = AdaBoostClassifier(algorithm='SAMME', learning_rate=0.01, n_estimators=15)\n",
    "model.fit(X_train_sc, y_train)\n",
    "importance_df = pd.DataFrame({'Feature': X_train.columns,\n",
    "                              'Importance': model.feature_importances_}) \\\n",
    "                            .sort_values(by='Importance', ascending=False)\n",
    "importance_df\n",
    "# Nettfa is the feature with the highest predictive power."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 25. Based on training f1-score and testing f1-score, is there evidence of overfitting in any of your models? Which ones?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "BaggingClassifier, which tends to overfit as evidenced by a 0.35 difference between training and testing F1-scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 26. Based on everything we've covered so far, if you had to pick just one model as your final model to use to answer the problem in front of you, which one model would you pick? Defend your choice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "RandomForestClassifier, as it performs well for both regression and classification tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 27. Suppose you wanted to improve the performance of your final model. Brainstorm 2-3 things that, if you had more time, you would attempt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "- Conduct research into potential new features\n",
    "- Refine hyperparameters through GridSearch\n",
    "- Perform feature engineering and selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Answer the problem.\n",
    "\n",
    "##### BONUS: Briefly summarize your answers to the regression and classification problems. Be sure to include any limitations or hesitations in your answer.\n",
    "\n",
    "- Regression: What features best predict one's income?\n",
    "- Classification: Predict whether or not one is eligible for a 401k."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "* Regression: RandomForestRegressor achieved the highest R^2 score\n",
    "  * The model's performance is suboptimal, with an R^2 of 0.39 and a significant difference of 0.04 between training and testing scores, suggesting overfitting.\n",
    "  * `nettfa` is the feature with the highest predictive power for the income.\n",
    "* Classification: AdaBoostClassifier achieved the highest F1 score\n",
    "  * `nettfa` is the feature with the highest predictive power for the `e401k`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
