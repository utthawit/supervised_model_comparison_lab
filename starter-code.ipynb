{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Supervised Learning Model Comparison\n",
    "\n",
    "---\n",
    "\n",
    "### Let us begin...\n",
    "\n",
    "Recall the `data science process`.\n",
    "   1. Define the problem.\n",
    "   2. Gather the data.\n",
    "   3. Explore the data.\n",
    "   4. Model the data.\n",
    "   5. Evaluate the model.\n",
    "   6. Answer the problem.\n",
    "\n",
    "In this lab, we're going to focus mostly on creating (and then comparing) many regression and classification models. Thus, we'll define the problem and gather the data for you.\n",
    "Most of the questions requiring a written response can be written in 2-3 sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Define the problem.\n",
    "\n",
    "You are a data scientist with a financial services company. Specifically, you want to leverage data in order to identify potential customers.\n",
    "\n",
    "If you are unfamiliar with \"401(k)s\" or \"IRAs,\" these are two types of retirement accounts. Very broadly speaking:\n",
    "- You can put money for retirement into both of these accounts.\n",
    "- The money in these accounts gets invested and hopefully has a lot more money in it when you retire.\n",
    "- These are a little different from regular bank accounts in that there are certain tax benefits to these accounts. Also, employers frequently match money that you put into a 401k.\n",
    "- If you want to learn more about them, check out [this site](https://www.nerdwallet.com/article/ira-vs-401k-retirement-accounts).\n",
    "\n",
    "We will tackle one regression problem and one classification problem today.\n",
    "- Regression: What features best predict one's income?\n",
    "- Classification: Predict whether or not one is eligible for a 401k.\n",
    "\n",
    "Check out the data dictionary [here](http://fmwww.bc.edu/ec-p/data/wooldridge2k/401KSUBS.DES).\n",
    "\n",
    "#### NOTE: When predicting `inc`, you should pretend as though you do not have access to the `e401k`, the `p401k` variable, and the `pira` variable. \n",
    "\n",
    "#### When predicting `e401k`, you may use the entire dataframe if you wish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import root_mean_squared_error, make_scorer, f1_score\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor, KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingRegressor, RandomForestRegressor, AdaBoostRegressor, \\\n",
    "BaggingClassifier, RandomForestClassifier, AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Gather the data.\n",
    "\n",
    "##### 1. Read in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "d401k_df = pd.read_csv('401ksubs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>e401k</th>\n",
       "      <th>inc</th>\n",
       "      <th>marr</th>\n",
       "      <th>male</th>\n",
       "      <th>age</th>\n",
       "      <th>fsize</th>\n",
       "      <th>nettfa</th>\n",
       "      <th>p401k</th>\n",
       "      <th>pira</th>\n",
       "      <th>incsq</th>\n",
       "      <th>agesq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>13.170</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>4.575</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>173.4489</td>\n",
       "      <td>1600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>61.230</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>154.000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3749.1130</td>\n",
       "      <td>1225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>12.858</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>165.3282</td>\n",
       "      <td>1936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>98.880</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>21.800</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9777.2540</td>\n",
       "      <td>1936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>22.614</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>18.450</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>511.3930</td>\n",
       "      <td>2809</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   e401k     inc  marr  male  age  fsize   nettfa  p401k  pira      incsq  \\\n",
       "0      0  13.170     0     0   40      1    4.575      0     1   173.4489   \n",
       "1      1  61.230     0     1   35      1  154.000      1     0  3749.1130   \n",
       "2      0  12.858     1     0   44      2    0.000      0     0   165.3282   \n",
       "3      0  98.880     1     1   44      2   21.800      0     0  9777.2540   \n",
       "4      0  22.614     0     0   53      1   18.450      0     0   511.3930   \n",
       "\n",
       "   agesq  \n",
       "0   1600  \n",
       "1   1225  \n",
       "2   1936  \n",
       "3   1936  \n",
       "4   2809  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# review sample\n",
    "d401k_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "e401k     0\n",
       "inc       0\n",
       "marr      0\n",
       "male      0\n",
       "age       0\n",
       "fsize     0\n",
       "nettfa    0\n",
       "p401k     0\n",
       "pira      0\n",
       "incsq     0\n",
       "agesq     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for null\n",
    "d401k_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. What are 2-3 other variables that, if available, would be helpful to have?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "- Debt: Total debt (loans, credit card debt)\n",
    "- Savings Rate: Percentage of income saved each year\n",
    "- Risk Tolerance: Individual's willingness to take on investment risk."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Suppose a peer recommended putting `race` into your model in order to better predict who to target when advertising IRAs and 401(k)s. Why would this be an unethical decision?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "It could lead to discriminatory practices, as certain racial groups might be excluded or targeted disproportionately, regardless of their actual financial needs or potential."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Explore the data.\n",
    "\n",
    "##### 4. When attempting to predict income, which feature(s) would we reasonably not use? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate income by taking the square root of incsq, which is derived from inc squared."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5. What two variables have already been created for us through feature engineering? Come up with a hypothesis as to why subject-matter experts may have done this.\n",
    "> This need not be a \"statistical hypothesis.\" Just brainstorm why SMEs (Subject Matter Experts) might have done this!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6. Looking at the data dictionary, one variable description appears to be an error. What is this error, and what do you think the correct value would be?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Model the data. (Part 1: Regression Problem)\n",
    "\n",
    "Recall:\n",
    "- Problem: What features best predict one's income?\n",
    "- When predicting `inc`, you should pretend as though you do not have access to the `e401k`, the `p401k` variable, and the `pira` variable.\n",
    "\n",
    "##### 7. List all modeling tactics we've learned that could be used to solve a regression problem (as of Wednesday afternoon of Week 6). For each tactic, identify whether it is or is not appropriate for solving this specific regression problem and explain why or why not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "Linear Regression: Suitable for linear relationships.\n",
    "Logistic Regression: Ideal for classification multi catagories.\n",
    "Decision Tree Regressor: Appropriate for multi catagories.\n",
    "Gradient Boosting\n",
    "Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 8. Regardless of your answer to number 7, fit at least one of each of the following models to attempt to solve the regression problem above:\n",
    "    - a multiple linear regression model\n",
    "    - a k-nearest neighbors model\n",
    "    - a decision tree\n",
    "    - a set of bagged decision trees\n",
    "    - a random forest\n",
    "    - an Adaboost model\n",
    "    \n",
    "> As always, be sure to do a train/test split! In order to compare modeling techniques, you should use the same train-test split on each. I recommend setting a random seed here.\n",
    "\n",
    "> You may find it helpful to set up a pipeline to try each modeling technique, but you are not required to do so!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize values\n",
    "\n",
    "X = d401k_df[['marr','male','age','agesq','fsize','nettfa']]\n",
    "y = d401k_df['inc']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale value\n",
    "sc = StandardScaler()\n",
    "X_train_sc = sc.fit_transform(X_train)\n",
    "X_test_sc = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_models = {\n",
    "    'LR': LinearRegression(),\n",
    "    'KNN': KNeighborsRegressor(),\n",
    "    'DCT': DecisionTreeRegressor(),\n",
    "    'BAG': BaggingRegressor(),\n",
    "    'RF': RandomForestRegressor(),\n",
    "    'ADA': AdaBoostRegressor(),\n",
    "}\n",
    "\n",
    "search_params = {\n",
    "    'LR': {},\n",
    "    'KNN': {'n_neighbors': [1, 3, 5]},\n",
    "    'DCT': {'max_depth': [None, 10, 20, 30]},\n",
    "    'BAG': {'n_estimators': [10, 20, 30]},\n",
    "    'RF': {'n_estimators': [10, 20, 30], 'max_depth': [None, 5, 10]},\n",
    "    'ADA': {'n_estimators': [10, 30, 30], 'learning_rate': [0.001, 0.01, 0.1]},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Estimator of LinearRegression() is LinearRegression()\n",
      "Best Score of LinearRegression() is 0.2831173210103005\n",
      "Training Score of LinearRegression() is 0.2925748369332385\n",
      "Testing Score of LinearRegression() is 0.27494825151995317\n",
      "--------------------------------------------------------------------------------\n",
      "Best Estimator of KNeighborsRegressor() is KNeighborsRegressor()\n",
      "Best Score of KNeighborsRegressor() is 0.27604850012650217\n",
      "Training Score of KNeighborsRegressor() is 0.5264497080618398\n",
      "Testing Score of KNeighborsRegressor() is 0.3240304833150578\n",
      "--------------------------------------------------------------------------------\n",
      "Best Estimator of DecisionTreeRegressor() is DecisionTreeRegressor(max_depth=10)\n",
      "Best Score of DecisionTreeRegressor() is 0.1838314512865303\n",
      "Training Score of DecisionTreeRegressor() is 0.5800285053196111\n",
      "Testing Score of DecisionTreeRegressor() is 0.2492557584641013\n",
      "--------------------------------------------------------------------------------\n",
      "Best Estimator of BaggingRegressor() is BaggingRegressor(n_estimators=30)\n",
      "Best Score of BaggingRegressor() is 0.2860748049647349\n",
      "Training Score of BaggingRegressor() is 0.8850761190580959\n",
      "Testing Score of BaggingRegressor() is 0.3042539303084657\n",
      "--------------------------------------------------------------------------------\n",
      "Best Estimator of RandomForestRegressor() is RandomForestRegressor(max_depth=5, n_estimators=10)\n",
      "Best Score of RandomForestRegressor() is 0.3970517234636082\n",
      "Training Score of RandomForestRegressor() is 0.43022521602608943\n",
      "Testing Score of RandomForestRegressor() is 0.38892085390617837\n",
      "--------------------------------------------------------------------------------\n",
      "Best Estimator of AdaBoostRegressor() is AdaBoostRegressor(learning_rate=0.1, n_estimators=10)\n",
      "Best Score of AdaBoostRegressor() is 0.3615059626212343\n",
      "Training Score of AdaBoostRegressor() is 0.3789786045438619\n",
      "Testing Score of AdaBoostRegressor() is 0.34820977427905775\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# testing model\n",
    "for name, model in test_models.items():\n",
    "    grid = GridSearchCV(estimator=model, param_grid=search_params[name], scoring='r2')\n",
    "    grid.fit(X_train_sc, y_train)\n",
    "    print(f\"Best Estimator of {model} is {grid.best_estimator_}\")\n",
    "    print(f\"Best Score of {model} is {grid.best_score_}\")\n",
    "    print(f\"Training Score of {model} is {grid.score(X_train_sc, y_train)}\")\n",
    "    print(f\"Testing Score of {model} is {grid.score(X_test_sc, y_test)}\")\n",
    "    print('-'*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 9. What is bootstrapping?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "Resampling technique used to estimate the variability of a statistic use to estimate model performance ot find feature importance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 10. What is the difference between a decision tree and a set of bagged decision trees? Be specific and precise!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "- Decision trees are single models that can be lead to overfitting.\n",
    "- Bagged decision trees are ensembles of multiple decision trees that can reduce overfitting and improve performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 11. What is the difference between a set of bagged decision trees and a random forest? Be specific and precise!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bagging and random forest are both ensemble techniques that use decision trees.\n",
    "- Bagging reduces variance by averaging multiple trees.\n",
    "- Random forest further improves performance by introducing feature randomness."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 12. Why might a random forest be superior to a set of bagged decision trees?\n",
    "> Hint: Consider the bias-variance tradeoff."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "Random forests are generally superior to bagged decision trees because they introduce additional randomness by considering only a subset of features at each split, further reducing correlation between trees and improving \n",
    "performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Evaluate the model. (Part 1: Regression Problem)\n",
    "\n",
    "##### 13. Using RMSE, evaluate each of the models you fit on both the training and testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RMSE is 18.05642420331128\n",
      "Testing RMSE is 19.100127767612996\n"
     ]
    }
   ],
   "source": [
    "# based on best model from item 8\n",
    "model = RandomForestRegressor(max_depth=5, n_estimators=30)\n",
    "model.fit(X_train_sc, y_train)\n",
    "y_train_pred = model.predict(X_train_sc)\n",
    "y_test_pred = model.predict(X_test_sc)\n",
    "print(f\"Training RMSE is {root_mean_squared_error(y_train, y_train_pred)}\")\n",
    "print(f\"Testing RMSE is {root_mean_squared_error(y_test, y_test_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 14. Based on training RMSE and testing RMSE, is there evidence of overfitting in any of your models? Which ones?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "It doesn't overfit, as the RMSE remains relatively the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 15. Based on everything we've covered so far, if you had to pick just one model as your final model to use to answer the problem in front of you, which one model would you pick? Defend your choice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "LinearRegression is a suitable model due to its strong performance and lack of overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 16. Suppose you wanted to improve the performance of your final model. Brainstorm 2-3 things that, if you had more time, you would attempt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "- Researh for new features\n",
    "- Change GridSearch hyper-parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Model the data. (Part 2: Classification Problem)\n",
    "\n",
    "Recall:\n",
    "- Problem: Predict whether or not one is eligible for a 401k.\n",
    "- When predicting `e401k`, you may use the entire dataframe if you wish.\n",
    "\n",
    "##### 17. While you're allowed to use every variable in your dataframe, mention at least one disadvantage of using `p401k` in your model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "- It trend to overfit our model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 18. List all modeling tactics we've learned that could be used to solve a classification problem (as of Wednesday afternoon of Week 6). For each tactic, identify whether it is or is not appropriate for solving this specific classification problem and explain why or why not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Logistic Regression\n",
    "- KNN\n",
    "- Decision Tree\n",
    "- Random Forests\n",
    "- Adaboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 19. Regardless of your answer to number 18, fit at least one of each of the following models to attempt to solve the classification problem above:\n",
    "    - a logistic regression model\n",
    "    - a k-nearest neighbors model\n",
    "    - a decision tree\n",
    "    - a set of bagged decision trees\n",
    "    - a random forest\n",
    "    - an Adaboost model\n",
    "    \n",
    "> As always, be sure to do a train/test split! In order to compare modeling techniques, you should use the same train-test split on each. I recommend using a random seed here.\n",
    "\n",
    "> You may find it helpful to set up a pipeline to try each modeling technique, but you are not required to do so!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_models = {\n",
    "    'LR': LogisticRegression(),\n",
    "    'KNN': KNeighborsClassifier(),\n",
    "    'DCT': DecisionTreeClassifier(),\n",
    "    'BAG': BaggingClassifier(),\n",
    "    'RF': RandomForestClassifier(),\n",
    "    'ADA': AdaBoostClassifier()\n",
    "}\n",
    "\n",
    "search_params = {\n",
    "    'LR': {},\n",
    "    'KNN': {'n_neighbors': [1, 3, 5]},\n",
    "    'DCT': {'max_depth': [None, 10, 20, 30]},\n",
    "    'BAG': {'n_estimators': [10, 20, 30]},\n",
    "    'RF': {'n_estimators': [10, 20, 30], 'max_depth': [None, 5, 10]},\n",
    "    'ADA': {'n_estimators': [10, 30, 30], 'learning_rate': [0.001, 0.01, 0.1], 'algorithm': ['SAMME']},\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Evaluate the model. (Part 2: Classfication Problem)\n",
    "\n",
    "##### 20. Suppose our \"positive\" class is that someone is eligible for a 401(k). What are our false positives? What are our false negatives?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>e401k</th>\n",
       "      <th>inc</th>\n",
       "      <th>marr</th>\n",
       "      <th>male</th>\n",
       "      <th>age</th>\n",
       "      <th>fsize</th>\n",
       "      <th>nettfa</th>\n",
       "      <th>p401k</th>\n",
       "      <th>pira</th>\n",
       "      <th>incsq</th>\n",
       "      <th>agesq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>13.170</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>4.575</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>173.4489</td>\n",
       "      <td>1600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>61.230</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>154.000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3749.1130</td>\n",
       "      <td>1225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>12.858</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>165.3282</td>\n",
       "      <td>1936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>98.880</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>21.800</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9777.2540</td>\n",
       "      <td>1936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>22.614</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>18.450</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>511.3930</td>\n",
       "      <td>2809</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   e401k     inc  marr  male  age  fsize   nettfa  p401k  pira      incsq  \\\n",
       "0      0  13.170     0     0   40      1    4.575      0     1   173.4489   \n",
       "1      1  61.230     0     1   35      1  154.000      1     0  3749.1130   \n",
       "2      0  12.858     1     0   44      2    0.000      0     0   165.3282   \n",
       "3      0  98.880     1     1   44      2   21.800      0     0  9777.2540   \n",
       "4      0  22.614     0     0   53      1   18.450      0     0   511.3930   \n",
       "\n",
       "   agesq  \n",
       "0   1600  \n",
       "1   1225  \n",
       "2   1936  \n",
       "3   1936  \n",
       "4   2809  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d401k_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize values\n",
    "X = d401k_df[['marr','male','age','fsize']]\n",
    "y = d401k_df['e401k']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale value\n",
    "sc = StandardScaler()\n",
    "X_train_sc = sc.fit_transform(X_train)\n",
    "X_test_sc = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Estimator of LogisticRegression() is LogisticRegression()\n",
      "Best Score of LogisticRegression() is 0.607277628032345\n",
      "Training Score of LogisticRegression() is 0.607277628032345\n",
      "Testing Score of LogisticRegression() is 0.6102425876010782\n",
      "Difference Training/Testing Score of LogisticRegression() is -0.0029649595687332164\n",
      "--------------------------------------------------------------------------------\n",
      "Best Estimator of KNeighborsClassifier() is KNeighborsClassifier()\n",
      "Best Score of KNeighborsClassifier() is 0.5623989218328841\n",
      "Training Score of KNeighborsClassifier() is 0.6040431266846361\n",
      "Testing Score of KNeighborsClassifier() is 0.5455525606469003\n",
      "Difference Training/Testing Score of KNeighborsClassifier() is 0.058490566037735836\n",
      "--------------------------------------------------------------------------------\n",
      "Best Estimator of DecisionTreeClassifier() is DecisionTreeClassifier(max_depth=10)\n",
      "Best Score of DecisionTreeClassifier() is 0.592722371967655\n",
      "Training Score of DecisionTreeClassifier() is 0.6331536388140162\n",
      "Testing Score of DecisionTreeClassifier() is 0.6043126684636119\n",
      "Difference Training/Testing Score of DecisionTreeClassifier() is 0.028840970350404338\n",
      "--------------------------------------------------------------------------------\n",
      "Best Estimator of BaggingClassifier() is BaggingClassifier(n_estimators=30)\n",
      "Best Score of BaggingClassifier() is 0.5766846361185984\n",
      "Training Score of BaggingClassifier() is 0.6567385444743935\n",
      "Testing Score of BaggingClassifier() is 0.6\n",
      "Difference Training/Testing Score of BaggingClassifier() is 0.056738544474393526\n",
      "--------------------------------------------------------------------------------\n",
      "Best Estimator of RandomForestClassifier() is RandomForestClassifier(max_depth=5, n_estimators=30)\n",
      "Best Score of RandomForestClassifier() is 0.607277628032345\n",
      "Training Score of RandomForestClassifier() is 0.6074123989218329\n",
      "Testing Score of RandomForestClassifier() is 0.6102425876010782\n",
      "Difference Training/Testing Score of RandomForestClassifier() is -0.002830188679245338\n",
      "--------------------------------------------------------------------------------\n",
      "Best Estimator of AdaBoostClassifier() is AdaBoostClassifier(algorithm='SAMME', learning_rate=0.001, n_estimators=10)\n",
      "Best Score of AdaBoostClassifier() is 0.607277628032345\n",
      "Training Score of AdaBoostClassifier() is 0.607277628032345\n",
      "Testing Score of AdaBoostClassifier() is 0.6102425876010782\n",
      "Difference Training/Testing Score of AdaBoostClassifier() is -0.0029649595687332164\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# testing model\n",
    "for name, model in test_models.items():\n",
    "    grid = GridSearchCV(estimator=model, param_grid=search_params[name])\n",
    "    grid.fit(X_train_sc, y_train)\n",
    "    print(f\"Best Estimator of {model} is {grid.best_estimator_}\")\n",
    "    print(f\"Best Score of {model} is {grid.best_score_}\")\n",
    "    print(f\"Training Score of {model} is {grid.score(X_train_sc, y_train)}\")\n",
    "    print(f\"Testing Score of {model} is {grid.score(X_test_sc, y_test)}\")\n",
    "    print(f\"Difference Training/Testing Score of {model} is {grid.score(X_train_sc, y_train) - grid.score(X_test_sc, y_test)}\")\n",
    "    print('-'*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 21. In this specific case, would we rather minimize false positives or minimize false negatives? Defend your choice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "- Minimizing false negatives is more desirable.\n",
    "- Result in an individual missing out on valuable retirement savings opportunities, potentially leading to financial hardship in their later years."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 22. Suppose we wanted to optimize for the answer you provided in problem 21. Which metric would we optimize in this case?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Specificity measures the proportion of actual negatives that are correctly identified as negative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 23. Suppose that instead of optimizing for the metric in problem 21, we wanted to balance our false positives and false negatives using `f1-score`. Why might [f1-score](https://en.wikipedia.org/wiki/F1_score) be an appropriate metric to use here?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F1 provides a balanced measure of both false positives and false negatives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 24. Using f1-score, evaluate each of the models you fit on both the training and testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Estimator of LogisticRegression() is LogisticRegression()\n",
      "Best Score of LogisticRegression() is 0.0\n",
      "Training F1-Score of LogisticRegression() is 0.00000000\n",
      "Testing F1-Score of LogisticRegression() is 0.00000000\n",
      "Difference Training/Testing F1-Score of LogisticRegression() is 0.00000000\n",
      "--------------------------------------------------------------------------------\n",
      "Best Estimator of KNeighborsClassifier() is KNeighborsClassifier(n_neighbors=1)\n",
      "Best Score of KNeighborsClassifier() is 0.39376368266664663\n",
      "Training F1-Score of KNeighborsClassifier() is 0.46732195\n",
      "Testing F1-Score of KNeighborsClassifier() is 0.41895604\n",
      "Difference Training/Testing F1-Score of KNeighborsClassifier() is 0.04836591\n",
      "--------------------------------------------------------------------------------\n",
      "Best Estimator of DecisionTreeClassifier() is DecisionTreeClassifier()\n",
      "Best Score of DecisionTreeClassifier() is 0.3317572126415903\n",
      "Training F1-Score of DecisionTreeClassifier() is 0.44920944\n",
      "Testing F1-Score of DecisionTreeClassifier() is 0.33452594\n",
      "Difference Training/Testing F1-Score of DecisionTreeClassifier() is 0.11468350\n",
      "--------------------------------------------------------------------------------\n",
      "Best Estimator of BaggingClassifier() is BaggingClassifier(n_estimators=20)\n",
      "Best Score of BaggingClassifier() is 0.34979174101130256\n",
      "Training F1-Score of BaggingClassifier() is 0.45988176\n",
      "Testing F1-Score of BaggingClassifier() is 0.35528596\n",
      "Difference Training/Testing F1-Score of BaggingClassifier() is 0.10459579\n",
      "--------------------------------------------------------------------------------\n",
      "Best Estimator of RandomForestClassifier() is RandomForestClassifier(n_estimators=20)\n",
      "Best Score of RandomForestClassifier() is 0.35323890820154685\n",
      "Training F1-Score of RandomForestClassifier() is 0.46663887\n",
      "Testing F1-Score of RandomForestClassifier() is 0.35536481\n",
      "Difference Training/Testing F1-Score of RandomForestClassifier() is 0.11127406\n",
      "--------------------------------------------------------------------------------\n",
      "Best Estimator of AdaBoostClassifier() is AdaBoostClassifier(algorithm='SAMME', learning_rate=0.001, n_estimators=10)\n",
      "Best Score of AdaBoostClassifier() is 0.0\n",
      "Training F1-Score of AdaBoostClassifier() is 0.00000000\n",
      "Testing F1-Score of AdaBoostClassifier() is 0.00000000\n",
      "Difference Training/Testing F1-Score of AdaBoostClassifier() is 0.00000000\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# testing model with F1 score\n",
    "for name, model in test_models.items():\n",
    "    grid = GridSearchCV(estimator=model, param_grid=search_params[name], scoring='f1')\n",
    "    grid.fit(X_train, y_train)\n",
    "    \n",
    "    best_mode = grid.best_estimator_\n",
    "    best_mode.fit(X_train_sc, y_train)\n",
    "    y_train_pred = best_mode.predict(X_train_sc)\n",
    "    y_test_pred = best_mode.predict(X_test_sc)\n",
    "    print(f\"Best Estimator of {model} is {grid.best_estimator_}\")\n",
    "    print(f\"Best Score of {model} is {grid.best_score_}\")\n",
    "    print(f\"Training F1-Score of {model} is {f1_score(y_train, y_train_pred):.8f}\")\n",
    "    print(f\"Testing F1-Score of {model} is {f1_score(y_test, y_test_pred):.8f}\")\n",
    "    print(f\"Difference Training/Testing F1-Score of {model} is {f1_score(y_train, y_train_pred) - f1_score(y_test, y_test_pred):.8f}\")\n",
    "    print('-'*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 25. Based on training f1-score and testing f1-score, is there evidence of overfitting in any of your models? Which ones?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "KNeighborsClassifier, which tends to overfit as evidenced by a 0.048 difference between training and testing F1-scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 26. Based on everything we've covered so far, if you had to pick just one model as your final model to use to answer the problem in front of you, which one model would you pick? Defend your choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 27. Suppose you wanted to improve the performance of your final model. Brainstorm 2-3 things that, if you had more time, you would attempt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Answer the problem.\n",
    "\n",
    "##### BONUS: Briefly summarize your answers to the regression and classification problems. Be sure to include any limitations or hesitations in your answer.\n",
    "\n",
    "- Regression: What features best predict one's income?\n",
    "- Classification: Predict whether or not one is eligible for a 401k."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
